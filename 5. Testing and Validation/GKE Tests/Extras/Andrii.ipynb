{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.dates import DateFormatter, SecondLocator\n",
    "\n",
    "# Plot 1: Succeeded Jobs\n",
    "with open('unique_jobs_24.txt', 'r') as file:\n",
    "    succeeded_data = file.readlines()\n",
    "\n",
    "# Extracting succeeded timestamps\n",
    "succeeded_timestamps = [line.split()[5] for line in succeeded_data if line.split()[5] != \"<none>\"]\n",
    "succeeded_timestamps = [ts.split(',')[0] for ts in succeeded_timestamps]  # Extract only the first timestamp\n",
    "succeeded_timestamps = pd.to_datetime(succeeded_timestamps, errors='coerce')  # Use errors='coerce' to handle parsing errors\n",
    "\n",
    "# Extracting first succeeded timestamp\n",
    "first_succeeded_timestamp = succeeded_timestamps.dropna().min()\n",
    "\n",
    "succeeded_counts = succeeded_timestamps.value_counts().sort_index()\n",
    "\n",
    "# Plot 2: Running and Pending Jobs\n",
    "with open('running_24_nodes_job.txt', 'r') as file:\n",
    "    running_data = file.readlines()\n",
    "\n",
    "timestamps_running = []\n",
    "cumulative_sum_running = 0\n",
    "encountered_jobs_running = set()\n",
    "\n",
    "for line in running_data:\n",
    "    parts = line.split()\n",
    "    job_id = parts[0]\n",
    "    if job_id in encountered_jobs_running:\n",
    "        continue\n",
    "    \n",
    "    start_time = pd.to_datetime(parts[3])\n",
    "    finish_time_str = parts[5].split(',')[0]\n",
    "    \n",
    "    if finish_time_str != '<none>':\n",
    "        finish_time = pd.to_datetime(finish_time_str)\n",
    "        timestamps_running.append((start_time, 1))\n",
    "        timestamps_running.append((finish_time, -1))\n",
    "        encountered_jobs_running.add(job_id)\n",
    "\n",
    "timestamps_running.sort()\n",
    "\n",
    "x_running = []\n",
    "y_running = []\n",
    "for timestamp in timestamps_running:\n",
    "    cumulative_sum_running += timestamp[1]\n",
    "    x_running.append(timestamp[0])\n",
    "    y_running.append(cumulative_sum_running)\n",
    "\n",
    "with open('pending_24_nodes_job.txt', 'r') as file:\n",
    "    pending_data = file.readlines()\n",
    "\n",
    "timestamps_pending = []\n",
    "cumulative_sum_pending = 0\n",
    "encountered_jobs_pending = set()\n",
    "\n",
    "for line in pending_data:\n",
    "    parts = line.split()\n",
    "    job_id = parts[0]\n",
    "    if job_id in encountered_jobs_pending:\n",
    "        continue\n",
    "    \n",
    "    start_time_str = parts[2]\n",
    "    if start_time_str == '<none>':\n",
    "        continue\n",
    "    \n",
    "    start_time = pd.to_datetime(start_time_str)\n",
    "    finish_time_str = parts[3].split(',')[0]\n",
    "    \n",
    "    if finish_time_str != '<none>':\n",
    "        finish_time = pd.to_datetime(finish_time_str)\n",
    "        timestamps_pending.append((start_time, 1))\n",
    "        timestamps_pending.append((finish_time, -1))\n",
    "        encountered_jobs_pending.add(job_id)\n",
    "\n",
    "timestamps_pending.sort()\n",
    "\n",
    "x_pending = []\n",
    "y_pending = []\n",
    "for timestamp in timestamps_pending:\n",
    "    cumulative_sum_pending += timestamp[1]\n",
    "    x_pending.append(timestamp[0])\n",
    "    y_pending.append(cumulative_sum_pending)\n",
    "\n",
    "# Plot 3: Total Number of Unique Jobs Over Time\n",
    "data = pd.read_csv('agc-24-3700-240326-1510-exp3.txt', sep='\\s{2,}', engine='python')\n",
    "data = data[data['NAME'].str.startswith('reana-run-job-')].drop_duplicates(subset=['NAME'])\n",
    "data['CREATED'] = pd.to_datetime(data['CREATED'])\n",
    "job_counts = data.groupby('CREATED').size().cumsum()\n",
    "\n",
    "# Plotting the data\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Plot succeeded jobs\n",
    "plt.plot(succeeded_counts.index, succeeded_counts.cumsum(), label='Finished', linestyle='-', color='green', alpha=0.5)\n",
    "\n",
    "# Plot first succeeded job\n",
    "#plt.axvline(x=first_succeeded_timestamp, color='red', linestyle='--', label='First Succeeded Job')\n",
    "\n",
    "# Plot running jobs\n",
    "plt.plot(x_running, y_running, linestyle='-', color='blue', alpha=0.5, linewidth=3, label='Running')\n",
    "\n",
    "# Plot pending jobs\n",
    "plt.plot(x_pending, y_pending, linestyle='-', color='orange', alpha=0.5, linewidth=3, label='Pending')\n",
    "\n",
    "# Plot total number of unique jobs over time\n",
    "plt.plot(job_counts.index, job_counts.values, linestyle='-', color='purple', label='Created')\n",
    "\n",
    "plt.xlabel('Processing time')\n",
    "plt.ylabel('Number of Jobs')\n",
    "plt.title(\"AGC CMS ttbar analysis running on REANA on 24 nodes (8 vCPU, 16 GiB RAM) requesting 3.7GiB per job\")\n",
    "plt.gca().xaxis.set_major_formatter(DateFormatter(\"%H:%M:%S\"))\n",
    "plt.gca().xaxis.set_major_locator(SecondLocator(interval=40))\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Open the input file for reading\n",
    "with open('agc-48-3700-240404-0840-exp3-a-1.txt', 'r') as f:\n",
    "    lines = f.readlines()  # Read all lines from the file\n",
    "\n",
    "# Initialize a dictionary to store the last unique \"reana-run-job\" entries\n",
    "unique_jobs = {}\n",
    "\n",
    "# Extract \"reana-run-job\" entries from the lines\n",
    "for line in lines:\n",
    "    if line.strip().startswith('reana-run-job-'):\n",
    "        job_id = line.strip().split()[0]  # Extract the job ID\n",
    "        unique_jobs[job_id] = line.strip()  # Store the latest entry for this job ID\n",
    "\n",
    "# Write the unique \"reana-run-job\" entries to a new file\n",
    "with open('unique_jobs_48.txt', 'w') as f:\n",
    "    for job in unique_jobs.values():\n",
    "        f.write(job + '\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Collection of starting \n",
    "with open('unique_jobs_3_1.txt', 'r') as f:\n",
    "    lines = f.readlines()  \n",
    "\n",
    "formatted_times = []\n",
    "\n",
    "\n",
    "for line in lines:\n",
    "    timestamp = line.strip().split()[4]\n",
    "    time_part = timestamp.split('T')[1].split('Z')[0]\n",
    "    formatted_times.append(time_part)\n",
    "\n",
    "with open('started_time_3.txt', 'w') as f:\n",
    "    for time in formatted_times:\n",
    "        f.write(time + '\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data from the text file\n",
    "with open('agc-3-1850-240410-1000-exp3-1.txt', 'r') as file:\n",
    "    data = file.readlines()\n",
    "\n",
    "# Sort the data based on job status (Pending, Running)\n",
    "sorted_data = sorted(data, key=lambda x: x.split()[1])\n",
    "\n",
    "# Filter pending jobs and save them to a separate text file\n",
    "pending_jobs = [line for line in sorted_data if line.split()[1] == 'Pending']\n",
    "with open('pending_3nodes_job_exp5.txt', 'w') as file:\n",
    "    file.writelines(pending_jobs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data from the text file\n",
    "with open('agc-3-1850-240410-1000-exp3-1.txt', 'r') as file:\n",
    "    data = file.readlines()\n",
    "\n",
    "# Sort the data based on job status (Pending, Running)\n",
    "sorted_data = sorted(data, key=lambda x: x.split()[1])\n",
    "\n",
    "# Filter pending jobs and save them to a separate text file\n",
    "running_jobs = [line for line in sorted_data if line.split()[1] == 'Running']\n",
    "with open('running_3nodes_job_exp5.txt', 'w') as file:\n",
    "    file.writelines(running_jobs)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
